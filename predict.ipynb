{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd02efabeff3d88b4fed4541d07ce028a3ba12f36779da6a6ecd8c4c78056155e5c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_df = pd.read_csv(\"data/lectures.csv\")\n",
    "question_df = pd.read_csv(\"data/questions.csv\")\n",
    "response_df = pd.read_csv(\"data/responses.csv\")\n",
    "train_df = pd.read_csv(\"data/short_train.csv\")"
   ]
  },
  {
   "source": [
    "### Split Train Data\n",
    "\n",
    "Split the train data on `content_type_id` (whether it was an exam or a lecture)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exam_filter = train_df['content_type_id'] == 0\n",
    "train_lecture_filter = train_df['content_type_id'] == 1\n",
    "\n",
    "train_exams_df = train_df[train_exam_filter]\n",
    "train_lectures_df = train_df[train_lecture_filter]"
   ]
  },
  {
   "source": [
    "Print a report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Exams\n=====\nrow count: 343298\nuser count: 1215\n\nLectures\n========\nrow count: 6701\nuser count: 505\n"
     ]
    }
   ],
   "source": [
    "print('Exams', end='\\n=====\\n')\n",
    "print(f'row count: {len(train_exams_df)}')\n",
    "print(f'user count: {len(train_exams_df.groupby([\"user_id\"]))}')\n",
    "\n",
    "print()\n",
    "\n",
    "print('Lectures', end='\\n========\\n')\n",
    "print(f'row count: {len(train_lectures_df)}')\n",
    "print(f'user count: {len(train_lectures_df.groupby([\"user_id\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, user_id, content_id, task_container_id, answered_correctly, prior_question_elapsed_time, prior_question_had_explanation):\n",
    "        self.user_id = user_id\n",
    "        self.content_id = content_id\n",
    "        self.task_container_id = task_container_id\n",
    "        self.answered_correctly = answered_correctly\n",
    "        self.prior_question_elapsed_time = prior_question_elapsed_time\n",
    "        self.prior_question_had_explanation = prior_question_had_explanation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/slim_train.csv'\n",
    "users = []\n",
    "with open(file_name, 'r', encoding=\"utf-8\") as in_file:\n",
    "    for i, line in enumerate(in_file):\n",
    "\n",
    "        # Skip headers\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        line = line.split(',')\n",
    "\n",
    "        user_id = int(line[0])\n",
    "        content_id = int(line[1])\n",
    "        task_container_id = int(line[2])\n",
    "        answered_correctly = int(line[3]) == 1\n",
    "        prior_question_elapsed_time = int(line[4])\n",
    "        prior_question_had_explanation = bool(line[5])\n",
    "\n",
    "        users.append(User(user_id, content_id, task_container_id, answered_correctly, prior_question_elapsed_time, prior_question_had_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "230009\n113289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(users, test_size=0.33, random_state=42)\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_train = [user.user_id for user in training_data]\n",
    "timestamp_train = [user.timestamp for user in training_data]\n",
    "answered_correctly_train = [user.answered_correctly for user in training_data]\n",
    "\n",
    "user_id_test = [user.user_id for user in test_data]\n",
    "timestamp_test = [user.timestamp for user in test_data]\n",
    "answered_correctly_test = [user.answered_correctly for user in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "answered correctly: 153737\nanswered incorrectly: 76272\n"
     ]
    }
   ],
   "source": [
    "print(f'answered correctly: {answered_correctly_train.count(True)}')\n",
    "print(f'answered incorrectly: {answered_correctly_train.count(False)}')"
   ]
  },
  {
   "source": [
    "### Training the algorithm!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Define helper classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class Entry:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__ = kwargs"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "Read from CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/slim_train.csv'\n",
    "entries = []\n",
    "with open(path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        # Skip header\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        u_id, c_id, tc_id, answered_correctly, pqet, pqhe = line.split(',')\n",
    "\n",
    "        entries.append(Entry(\n",
    "            user_id=u_id,\n",
    "            content_id=c_id,\n",
    "            task_container_id=tc_id,\n",
    "            answered_correctly=True if answered_correctly == '1' else False,\n",
    "            prior_question_elapsed_time=float(pqet),\n",
    "            prior_question_had_explanation=bool(pqhe)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Entry count: 343298\n"
     ]
    }
   ],
   "source": [
    "print(f'Entry count: {len(entries)}')"
   ]
  },
  {
   "source": [
    "Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training_data count: 230009\ntest_data count: 113289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(entries, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f'training_data count: {len(training_data)}')\n",
    "print(f'test_data count: {len(test_data)}')"
   ]
  },
  {
   "source": [
    "Split into X and Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_x = [dict(\n",
    "    user_id=entry.user_id,\n",
    "    content_id=entry.content_id,\n",
    "    task_container_id=entry.task_container_id,\n",
    "    prior_question_elapsed_time=entry.prior_question_elapsed_time,\n",
    "    prior_question_had_explanation=entry.prior_question_had_explanation\n",
    ") for entry in training_data]\n",
    "\n",
    "train_y = [entry.answered_correctly for entry in training_data]\n",
    "\n",
    "# Test\n",
    "test_x = [dict(\n",
    "    user_id=entry.user_id,\n",
    "    content_id=entry.content_id,\n",
    "    task_container_id=entry.task_container_id,\n",
    "    prior_question_elapsed_time=entry.prior_question_elapsed_time,\n",
    "    prior_question_had_explanation=entry.prior_question_had_explanation\n",
    ") for entry in test_data]\n",
    "\n",
    "test_y = [entry.answered_correctly for entry in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "correct: 153737\nincorrect: 76272\n"
     ]
    }
   ],
   "source": [
    "print(f'correct: {train_y.count(True)}')\n",
    "print(f'incorrect: {train_y.count(False)}')"
   ]
  },
  {
   "source": [
    "Determine the best algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "source": [
    "Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier accuracy: 0.6550680118987722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_cls = DecisionTreeClassifier()\n",
    "dec_cls.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(f'DecisionTreeClassifier accuracy: {dec_cls.score(test_x_vectors, test_y)}')"
   ]
  },
  {
   "source": [
    "Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression accuracy: 0.7117372383903116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_cls = LogisticRegression(max_iter=2000)\n",
    "log_cls.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(f'LogisticRegression accuracy: {log_cls.score(test_x_vectors, test_y)}')"
   ]
  },
  {
   "source": [
    "### Test the algorithm!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The user is predicted to answer: correctly\n"
     ]
    }
   ],
   "source": [
    "u_id = input('user id: ')\n",
    "c_id = input('content id: ')\n",
    "tc_id = input('task container id: ')\n",
    "pqet = float(input('prior question elapsed time: '))\n",
    "pqhe = bool(input('prior question had explanation: '))\n",
    "\n",
    "input_dict = dict(\n",
    "    user_id=u_id,\n",
    "    content_id=c_id,\n",
    "    task_container_id=tc_id,\n",
    "    prior_question_elapsed_time=pqet,\n",
    "    prior_question_had_explanation=pqhe\n",
    ")\n",
    "input_vector = vectorizer.transform(input_dict)\n",
    "\n",
    "prediction = log_cls.predict(input_vector)\n",
    "print(f'The user is predicted to answer: {\"correctly\" if prediction[0] == 1 else \"incorrectly\"}')"
   ]
  }
 ]
}